{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# MNIST Visualization Example\n",
    "\n",
    "Real-time visualization of MNIST training on a CNN, using TensorFlow and [TensorDebugger](https://github.com/ericjang/tdb)\n",
    "\n",
    "The visualizations in this notebook won't show up on http://nbviewer.ipython.org. To view the widgets and interact with them, you will need to download this notebook and run it with a Jupyter Notebook server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Step 1: Load TDB Notebook Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "Jupyter.utils.load_extensions('tdb_ext/main')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "Jupyter.utils.load_extensions('tdb_ext/main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#import sys\n",
    "#sys.path.append('/home/evjang/thesis/tensor_debugger')\n",
    "import tdb\n",
    "from tdb.examples import mnist, viz\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Step 2: Build TensorFlow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/taesung/tensorflow_debegger/tdb/examples/mnist.py:90 in _activation_summary.: histogram_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.histogram. Note that tf.summary.histogram uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on their scope.\n",
      "WARNING:tensorflow:From /Users/taesung/tensorflow_debegger/tdb/examples/mnist.py:91 in _activation_summary.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:From /Users/taesung/tensorflow_debegger/tdb/examples/mnist.py:90 in _activation_summary.: histogram_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.histogram. Note that tf.summary.histogram uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on their scope.\n",
      "WARNING:tensorflow:From /Users/taesung/tensorflow_debegger/tdb/examples/mnist.py:91 in _activation_summary.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:From /Users/taesung/tensorflow_debegger/tdb/examples/mnist.py:151 in build_model.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:From /Users/taesung/tensorflow_debegger/tdb/examples/mnist.py:175 in build_model.: merge_all_summaries (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.merge_all.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/ops/logging_ops.py:264 in merge_all_summaries.: merge_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.merge.\n"
     ]
    }
   ],
   "source": [
    "(train_data_node,\n",
    "    train_labels_node,\n",
    "    validation_data_node,\n",
    "    test_data_node,\n",
    "    # predictions\n",
    "    train_prediction,\n",
    "    validation_prediction,\n",
    "    test_prediction,\n",
    "    # weights\n",
    "    conv1_weights,\n",
    "    conv2_weights,\n",
    "    fc1_weights,\n",
    "    fc2_weights,\n",
    "    # training\n",
    "    optimizer,\n",
    "    loss,\n",
    "    learning_rate,\n",
    "    summaries) = mnist.build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Step 3: Attach Plotting Ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def viz_activations(ctx, m):\n",
    "    plt.matshow(m.T,cmap=plt.cm.gray)\n",
    "    plt.title(\"LeNet Predictions\")\n",
    "    plt.xlabel(\"Batch\")\n",
    "    plt.ylabel(\"Digit Activation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# plotting a user-defined function 'viz_activations'\n",
    "p0=tdb.plot_op(viz_activations,inputs=[train_prediction])\n",
    "# weight variables are of type tf.Variable, so we need to find the corresponding tf.Tensor instead\n",
    "g=tf.get_default_graph()\n",
    "p1=tdb.plot_op(viz.viz_conv_weights,inputs=[g.as_graph_element(conv1_weights)])\n",
    "p2=tdb.plot_op(viz.viz_conv_weights,inputs=[g.as_graph_element(conv2_weights)])\n",
    "p3=tdb.plot_op(viz.viz_fc_weights,inputs=[g.as_graph_element(fc1_weights)])\n",
    "p4=tdb.plot_op(viz.viz_fc_weights,inputs=[g.as_graph_element(fc2_weights)])\n",
    "p2=tdb.plot_op(viz.viz_conv_hist,inputs=[g.as_graph_element(conv1_weights)])\n",
    "ploss=tdb.plot_op(viz.watch_loss,inputs=[loss])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Step 4: Download the MNIST dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "download_dir='/tmp/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Step 5: Debug + Visualize!\n",
    "\n",
    "Upon evaluating plot nodes p1,p2,p3,p4,ploss, plots will be generated in the Plot view on the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Extracting', '/tmp/train-images-idx3-ubyte.gz')\n",
      "('Extracting', '/tmp/train-labels-idx1-ubyte.gz')\n",
      "('Extracting', '/tmp/t10k-images-idx3-ubyte.gz')\n",
      "('Extracting', '/tmp/t10k-labels-idx1-ubyte.gz')\n"
     ]
    }
   ],
   "source": [
    "# return the TF nodes corresponding to graph input placeholders\n",
    "(train_data, \n",
    " train_labels, \n",
    " validation_data, \n",
    " validation_labels, \n",
    " test_data, \n",
    " test_labels) = mnist.get_data(download_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# start the TensorFlow session that will be used to evaluate the graph\n",
    "s=tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 29.668428\n",
      "loss: 15.986283\n",
      "loss: 11.244756\n",
      "loss: 9.824888\n",
      "loss: 7.973310\n",
      "loss: 9.449040\n",
      "loss: 7.332593\n",
      "loss: 8.696226\n",
      "loss: 7.706570\n",
      "loss: 8.593947\n",
      "loss: 5.699204\n",
      "loss: 5.700300\n",
      "loss: 6.644909\n",
      "loss: 6.749149\n",
      "loss: 7.342368\n",
      "loss: 7.751038\n",
      "loss: 5.516746\n",
      "loss: 6.156354\n",
      "loss: 4.406677\n",
      "loss: 6.611945\n",
      "loss: 6.291268\n",
      "loss: 7.014967\n",
      "loss: 5.420129\n",
      "loss: 4.760524\n",
      "loss: 6.231194\n",
      "loss: 6.593681\n",
      "loss: 6.832925\n",
      "loss: 6.213955\n",
      "loss: 9.738566\n",
      "loss: 5.006141\n",
      "loss: 5.334596\n",
      "loss: 4.383435\n",
      "loss: 4.704712\n",
      "loss: 8.500669\n",
      "loss: 5.702556\n",
      "loss: 4.981853\n",
      "loss: 6.532305\n",
      "loss: 4.912939\n",
      "loss: 6.412427\n",
      "loss: 5.285848\n",
      "loss: 7.193241\n",
      "loss: 7.242463\n",
      "loss: 7.303301\n",
      "loss: 6.262392\n",
      "loss: 5.274841\n",
      "loss: 7.229550\n",
      "loss: 7.066195\n",
      "loss: 6.615590\n",
      "loss: 6.835338\n",
      "loss: 3.897189\n",
      "loss: 6.059953\n",
      "loss: 6.176492\n",
      "loss: 8.691050\n",
      "loss: 5.851261\n",
      "loss: 6.193049\n",
      "loss: 6.202602\n",
      "loss: 5.082464\n",
      "loss: 9.191186\n",
      "loss: 7.092690\n",
      "loss: 6.742504\n",
      "loss: 5.157558\n",
      "loss: 7.217108\n",
      "loss: 5.997323\n",
      "loss: 4.921431\n",
      "loss: 6.982061\n",
      "loss: 6.096120\n",
      "loss: 6.371015\n",
      "loss: 5.135803\n",
      "loss: 5.194246\n",
      "loss: 6.375832\n",
      "loss: 4.955305\n",
      "loss: 5.327397\n",
      "loss: 6.256441\n",
      "loss: 7.047164\n",
      "loss: 5.855045\n",
      "loss: 5.046394\n",
      "loss: 5.635267\n",
      "loss: 6.704008\n",
      "loss: 5.561760\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 5\n",
    "TRAIN_SIZE=10000\n",
    "\n",
    "for step in range(NUM_EPOCHS * TRAIN_SIZE // BATCH_SIZE):\n",
    "    offset = (step * BATCH_SIZE) % (TRAIN_SIZE - BATCH_SIZE)\n",
    "    batch_data = train_data[offset:(offset + BATCH_SIZE), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + BATCH_SIZE)]\n",
    "    feed_dict = {\n",
    "        train_data_node: batch_data,\n",
    "        train_labels_node: batch_labels\n",
    "    }\n",
    "    # run training node and visualization node\n",
    "    status,result=tdb.debug([optimizer,p0], feed_dict=feed_dict, session=s)\n",
    "    if step % 10 == 0:  \n",
    "        status,result=tdb.debug([loss,p1,p2,p3,p4,ploss], feed_dict=feed_dict, breakpoints=None, break_immediately=False, session=s)\n",
    "        print('loss: %f' % (result[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
